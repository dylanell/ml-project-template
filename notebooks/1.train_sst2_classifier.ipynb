{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Train SST-2 Sentiment Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "### Inspect Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (67349, 2)\n",
      "Columns: ['sentence', 'label']\n",
      "Label distribution:\n",
      "label\n",
      "1    37569\n",
      "0    29780\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1\n",
       "3  remains utterly satisfied to remain the same t...      0\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\".data/sst2/train.tsv\", sep=\"\\t\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Label distribution:\\n{df['label'].value_counts()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "### Load as SequenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 67349\n",
      "Vocab size: 10002\n",
      "Classes: ['0', '1']\n"
     ]
    }
   ],
   "source": [
    "from ml_project_template.data import SequenceDataset\n",
    "\n",
    "dataset = SequenceDataset.from_csv(\n",
    "    \".data/sst2/train.tsv\",\n",
    "    text_column=\"sentence\",\n",
    "    label_column=\"label\",\n",
    "    max_vocab_size=10000,\n",
    ")\n",
    "\n",
    "print(f\"Samples: {len(dataset)}\")\n",
    "print(f\"Vocab size: {len(dataset.vocab)}\")\n",
    "print(f\"Classes: {dataset.class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length — min: 0, max: 48, mean: 8.9, p95: 24\n",
      "\n",
      "Raw text: hide new secretions from the parental units \n",
      "Token IDs: [4564, 87, 1, 33, 2, 7150, 8684]\n",
      "Decoded: ['hide', 'new', '<UNK>', 'from', 'the', 'parental', 'units']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sequence length distribution\n",
    "lengths = [len(s) for s in dataset.sequences]\n",
    "print(\n",
    "    f\"Sequence length — min: {min(lengths)}, \"\\\n",
    "    f\"max: {max(lengths)}, mean: {np.mean(lengths):.1f}, \"\\\n",
    "    f\"p95: {np.percentile(lengths, 95):.0f}\"\n",
    ")\n",
    "\n",
    "# Sample encoding\n",
    "idx = 0\n",
    "inv_vocab = {v: k for k, v in dataset.vocab.items()}\n",
    "print(f\"\\nRaw text: {df['sentence'].iloc[idx]}\")\n",
    "print(f\"Token IDs: {dataset.sequences[idx]}\")\n",
    "print(f\"Decoded: {[inv_vocab[i] for i in dataset.sequences[idx]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 60614 samples\n",
      "Val:   6735 samples\n"
     ]
    }
   ],
   "source": [
    "# Time-aware split — no shuffle, splits by position\n",
    "train_data, val_data = dataset.split(test_size=0.1)\n",
    "\n",
    "print(f\"Train: {len(train_data)} samples\")\n",
    "print(f\"Val:   {len(val_data)} samples\")\n",
    "\n",
    "# Both splits share the same vocabulary\n",
    "assert train_data.vocab is val_data.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable-length batch — X: torch.Size([16, 28]), y: torch.Size([16])\n",
      "(batch_size=32, seq_len=max length in this batch)\n"
     ]
    }
   ],
   "source": [
    "# Variable-length mode: sequences padded to longest in each batch\n",
    "train_loader = train_data.to_pytorch(batch_size=16, shuffle=True)\n",
    "\n",
    "X_batch, y_batch = next(iter(train_loader))\n",
    "print(f\"Variable-length batch — X: {X_batch.shape}, y: {y_batch.shape}\")\n",
    "print(f\"(batch_size=32, seq_len=max length in this batch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed-length batch — X: torch.Size([16, 32]), y: torch.Size([16])\n",
      "(batch_size=32, seq_len=64 always)\n"
     ]
    }
   ],
   "source": [
    "# Fixed-length mode: all sequences truncated/padded to seq_length\n",
    "train_loader_fixed = train_data.to_pytorch(batch_size=16, shuffle=True, seq_length=32)\n",
    "\n",
    "X_batch, y_batch = next(iter(train_loader_fixed))\n",
    "print(f\"Fixed-length batch — X: {X_batch.shape}, y: {y_batch.shape}\")\n",
    "print(f\"(batch_size=32, seq_len=64 always)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050b6c7",
   "metadata": {},
   "source": [
    "### List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3be8cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanelliott/workspace/ml-project-template/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gb_classifier', 'mlp_classifier']\n"
     ]
    }
   ],
   "source": [
    "from ml_project_template.models import ModelRegistry\n",
    "\n",
    "print(ModelRegistry.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b1ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_project_template.modules import SequenceCNN\n",
    "\n",
    "model = SequenceCNN(\n",
    "    embed_dims=[len(train_data.vocab), 64],\n",
    "    kernel_spec=[\n",
    "        [3, 16, 2],\n",
    "        [3, 32, 1],\n",
    "        [3, 64, 1]\n",
    "    ],\n",
    "    seq_length=32,\n",
    "    output_dim=3,\n",
    "    padding_idx=train_data.vocab['<PAD>'],\n",
    "    hidden_activation=\"Tanh\",\n",
    "    output_activation=\"Identity\",\n",
    "    use_bias=True\n",
    ")\n",
    "\n",
    "for batch in train_loader_fixed:\n",
    "    inputs, labels = batch\n",
    "    break\n",
    "\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d1e4530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceCNN(\n",
       "  (embedding): Embedding(10002, 64, padding_idx=0)\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 64), stride=(2, 1))\n",
       "    (1): Transpose()\n",
       "    (2): Tanh()\n",
       "    (3): Conv2d(1, 32, kernel_size=(3, 16), stride=(1, 1))\n",
       "    (4): Transpose()\n",
       "    (5): Tanh()\n",
       "    (6): Conv2d(1, 64, kernel_size=(3, 32), stride=(1, 1))\n",
       "    (7): Transpose()\n",
       "    (8): Identity()\n",
       "  )\n",
       "  (linear): Linear(in_features=704, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3efa07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0dc3e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef595f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ceabb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
